# CVE-2024-2887

## Description

Type index can exceed `kV8MaxWasmTypes`, leading to type confusion with v8 internal `HeapType`.

## Analysis

In `DecodeTypeSection()`

```cpp
void DecodeTypeSection() { 
    TypeCanonicalizer* type_canon = GetTypeCanonicalizer();
    uint32_t types_count = consume_count("types count", kV8MaxWasmTypes);

    for (uint32_t i = 0; ok() && i < types_count; ++i) {
        TRACE("DecodeType[%d] module+%d\n", i, static_cast<int>(pc_ - start_));
        uint8_t kind = read_u8<Decoder::FullValidationTag>(pc(), "type kind");
        size_t initial_size = module_->types.size();
        // ...
        if (kind == kWasmRecursiveTypeGroupCode) { 
            // ... 
            uint32_t group_size = 
                  consume_count("recursive group size", kV8MaxWasmTypes); 
            // ... 
            if (initial_size + group_size > kV8MaxWasmTypes) {
                errorf(pc(), "Type definition count exceeds maximum %zu", 
                      kV8MaxWasmTypes);  
                return; 
            } 
            // ... 
            for (uint32_t j = 0; j < group_size; j++) { 
                // ... 
                TypeDefinition type = consume_subtype_definition(); 
                module_->types[initial_size + j] = type; 
            } 
            // ... 
        }
    }
} 
```
We can have more than one recursive group, and the size of `types` will continue to grow. So finally the type index can exceed `kV8MaxWasmTypes` even though the `types_count` is less than `kV8MaxWasmTypes` in each group.

V8 will first validate the function before compiling it, in `v8::internal::wasm::WasmFullDecoder::DecodeGCOpcode()`
```cpp
      case kExprStructGet: {
        NON_CONST_ONLY
        FieldImmediate field(this, this->pc_ + opcode_length, validate);
        if (!this->Validate(this->pc_ + opcode_length, field)) return 0;
        ValueType field_type =
            field.struct_imm.struct_type->field(field.field_imm.index);
        if (!VALIDATE(!field_type.is_packed())) {
          this->DecodeError(
              "struct.get: Immediate field %d of type %d has packed type %s. "
              "Use struct.get_s or struct.get_u instead.",
              field.field_imm.index, field.struct_imm.index,
              field_type.name().c_str());
          return 0;
        }
        Value struct_obj = Pop(ValueType::RefNull(field.struct_imm.index));
        Value* value = Push(field_type);
        CALL_INTERFACE_IF_OK_AND_REACHABLE(StructGet, struct_obj, field, true,
                                           value);
        return opcode_length + field.length;
      }
```

The `Pop` function will check the type index
```cpp
  Pop(ValueTypes... expected_types) {
    constexpr int kCount = sizeof...(ValueTypes);
    EnsureStackArguments(kCount);
    DCHECK_LE(control_.back().stack_depth, stack_size());
    DCHECK_GE(stack_size() - control_.back().stack_depth, kCount);
    // Note: Popping from the {FastZoneVector} does not invalidate the old (now
    // out-of-range) elements.
    stack_.pop(kCount);
    auto ValidateAndGetNextArg = [this, i = 0](ValueType type) mutable {
      ValidateStackValue(i, stack_.end()[i], type);
      return stack_.end()[i++];
    };
    return {ValidateAndGetNextArg(expected_types)...};
  }
```
In `ValidateStackValue` it will call `IsSubtypeOf` to check the type index
```cpp
V8_INLINE bool IsSubtypeOf(ValueType subtype, ValueType supertype,
                           const WasmModule* module) {
  // If the types are trivially identical, exit early.
  if (V8_LIKELY(subtype == supertype)) return true;
  return IsSubtypeOfImpl(subtype, supertype, module, module);
}
```

Notice that when `subtype == supertype`, it will return `true` directly. Since we can craft a type index that is exactly the same as some internal `HeapType`, we can bypass the type check and make our struct type become subtype of the internal `HeapType`.
When creating a new object with `struct.new` in WebAssembly, it will can `RttCanon`, for example:
```cpp
  LiftoffRegister RttCanon(uint32_t type_index, LiftoffRegList pinned) {
    LiftoffRegister rtt = pinned.set(__ GetUnusedRegister(kGpReg, pinned));
    LOAD_TAGGED_PTR_INSTANCE_FIELD(rtt.gp(), ManagedObjectMaps, pinned);
    __ LoadTaggedPointer(
        rtt.gp(), rtt.gp(), no_reg,
        wasm::ObjectAccess::ElementOffsetInTaggedFixedArray(type_index));
    return rtt;
  }
```

the managed object maps is a fixed array created in `InstanceBuilder::Build()`
```cpp
MaybeHandle<WasmInstanceObject> InstanceBuilder::Build() {
    // ...
  Handle<FixedArray> non_shared_maps = isolate_->factory()->NewFixedArray(
      static_cast<int>(module_->types.size()));
  Handle<FixedArray> shared_maps =
      shared ? isolate_->factory()->NewFixedArray(
                   static_cast<int>(module_->types.size()))
             : Handle<FixedArray>();
  for (uint32_t index = 0; index < module_->types.size(); index++) {
    bool shared = module_->types[index].is_shared;
    CreateMapForType(isolate_, module_, index,
                     shared ? shared_trusted_data : trusted_data,
                     instance_object, shared ? shared_maps : non_shared_maps);
  }
    // ...
}
```

## Exploit

Pretty straightforward, see `pwn.js`
